\subsection{Research Challenges }

In this section we discuss the research challenges to support secure, real-time decisions on live data at global scale.


\subsection{Real-time Decisions on Live Data} 

Despite existing examples such high-frequency trading and real-time ad targeting, making real-time decisions on live data is hard. This difficulty is because these decisions need to simultaneously achieve high quality, low latency, and be secure. Next, we define and discuss each of these desirable attributes.

{\bf Quality}: In this context, by quality, we mean the ability to make complex decisions that are accurate and robust. Many decisions are non-trivial. For example, detecting attacks in the Internet, coordinating a fleet of flying drones, or fraud detection, involve all complex decisions. Furthermore, many of these decisions should be automated. Without a human in the loop, we need to make sure that these decisions are both accurate and robust. 

By accuracy, we mean the ability to minimize both false positives and negatives. The failure to do so may lead to undesirable outcomes. For example, in the case of a fraud detection system, not catching a fraudulent transaction or blocking a legitimate transaction can both lead to revenue loss for a credit card company~\cite{Sculley11}. 

Furthermore, decisions should be robust in the presence of noisy data or unforeseen inputs. For example, a system coordinating a fleet of drones will have to deal with the noisy inputs provided by the sensors of the drones (e.g., a blurry video feed during heavy rain). As another example, consider an application that aims to detect Internet attacks (e.g., viruses, worms). Since these attacks are continuously evolving, such an application will have to deal with unforeseen attacks.

{\bf Latency}:  Ideally, one would like to minimize both the update and the decision/query latencies. However, there is a trade-off between these latencies.  In general, the more of the decision process we materialize in advance the faster the decision. Indeed, in settings where the space of decisions is finite one can precompute all possible decisions. This option will minimize the decision latency at the cost of the update latency.  At the other extreme, one can directly query the (raw) input data. In this case, the update latency is zero, but the decision latency will be much higher.  In~\cite{crankshaw15} we began to explore this tradeoff in greater detail and identifying mechanisms to dynamically trade-off these two latencies.

{\bf Security}: To make increasingly better decisions, users and organizations amass even more data, leading to  disastrous confidentiality and privacy breaches when compromised. Hence, as the amount of data grows, the need for security and the impact of the lack of security expands as well. Security attacks have already reached vast amounts of private or confidential data~\cite{breaches2015}. For example, last year marked the largest theft of medical records to date when attackers managed to steal millions of medical records from two major health insurers, Anthem and Premera~\cite{AnthemBreach,AnthemLargest}. It is estimated that attackers stole records of 80 million people from Anthem, and records of 11 million people from Premera. The data stolen included names, SSNs, medical information, and financial information. Furthermore, governments everywhere are pushing for back-doors into public services and subpoena companies providing those services to access user information in the name of security. 

Security breaches and personal information leakages can undermine the trust of the users in a service or application. This mistrust might lead to the demise of a service, as it may cause user defection, or worse it may expose the service owner to costly litigations. On the flip side, strong privacy guarantees may attract more users, which will ultimately lead to better decisions and better services. Security can also provide a competitive advantage to a service.

In addition, more of these applications and services are being deployed in public clouds, such as Amazon Web Services, Microsoft Azure, or Google Compute Engine. As such, providing both data and computation integrity are critical to protect and secure these services against concerns regarding malicious employees of cloud providers, or tenants that share the same cloud infrastructure. While ensuring these security properties is difficult, the real challenge is doing so while preserving the functionality and the performance of these applications.

\subsection{One-off Solutions}

Virtually all state-of-the-art systems~\cite{Agarwal14, Graepel10, Ganjam15}  we have discussed so far are custom, they have taken a long time to build, and their development was expensive, in some cases costing billion of dollars. Such is the case for search engines, navigation systems, self-driving cars, voice personal assistants, high-frequency trading, and ad targeting. To the extent there exists general platforms in this space, such as Spark or Hadoop, they only provide a solution to part of the problem. They do not  provide an end-to-end secure real-time decision stack. Looking forward, we believe there is the potential for an explosion of applications incorporating real-time decision making on live data. However, if this potential is to be realized, we would need to make it much easier to build and maintain such applications. 
